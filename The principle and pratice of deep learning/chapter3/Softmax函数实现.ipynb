{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "Softmax函数的本质是将一个K维的任意实数向量，压缩（映射）成另一个K维的实数向量，其中向量中的每个元素取指都介于（0,1）范围内。\n",
    "<br/>\n",
    "Softmax是对逻辑回归（Logistic Regression, LR）的推广，逻辑回归用于处理二分类问题，其推广Softmax回归则用于处理多分类问题。如下图示，在数学上，Softmax函数会返回输出类的互斥概率分布，例如，网络的输出为（1,1,1,1），经过Softmax函数后输出为（0.25,0.25,0.25,0.25）。我们可以得到分类中唯一所属类别，因此通常把Softmax作为输出层的激活函数。\n",
    "$$\n",
    "softmax(x) = \\frac{e^{x_j}}{\\sum_{k=1}^{K}e^{x_k}}\n",
    "$$\n",
    "\n",
    "下面进一步举例说明。假设有一个多分类问题，但是我们只关心这些类别的最高得分的概率，那么会使用一个带有最大似然估计函数的Softmax输出层来获得所有类比输出概率的最大值。例如神经网络的分类有3个，分别为“野马”“河马”“斑马”，使用softmax作为输出层的激活函数最后只能得到一个最大的分类概率如野马（0.6），河马（0.1），斑马（0.3），其中最大值野马（0.6）。\n",
    "<br/>\n",
    "如果要求每次的输出都可以获得多个分类，例如希望神经网络的预测输出既像“河马”也像“野马”，那么我们不希望Softmax作为输出层，这里可以使用Sigmoid函数作为输出层的激活函数更合适，因为Sigmoid函数可以为每个类别的输出提供独立的概率。\n",
    "<br/>\n",
    "## 性质\n",
    "$$\n",
    "softmax(x) = softmax(x+c),其中c为实数\n",
    "$$\n",
    "Reference:\n",
    "* [Softmax Function wiki](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "* [Classification and Loss Evaluation - Softmax and Cross Entropy Loss](https://deepnotes.io/softmax-crossentropy)\n",
    "* [Word2Vec介绍：softmax函数的python实现](https://zhuanlan.zhihu.com/p/28991249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    对输入x的每一行计算softmax\n",
    "    参数：\n",
    "    x: 矩阵\n",
    "    返回值：\n",
    "    x: 对应矩阵\n",
    "    \"\"\"\n",
    "    origin_shape = x.shape\n",
    "    \n",
    "    if len(x.shape) > 1:\n",
    "        # 矩阵\n",
    "        tmp = np.max(x, axis=1)\n",
    "        x -= tmp.reshape((x.shape[0], 1))\n",
    "        x = np.exp(x)\n",
    "        tmp = np.sum(x, axis = 1) # 每行求和\n",
    "        x /= tmp.reshape((x.shape[0]), 1)\n",
    "        \n",
    "    else:\n",
    "        tmp = np.max(x)\n",
    "        x -= tmp\n",
    "        x = np.exp(x)\n",
    "        tmp = np.sum(x)\n",
    "        x /= tmp\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[0.01165623 0.03168492 0.08612854 0.23412166 0.63640865]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([1,2,3,4,5])\n",
    "print(test)\n",
    "print(softmax(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
