# 命名实体识别综述

## 一、命名实体识别简介

### 1. 命名实体识别

#### 1.1 命名实体

命名实体是一个能够清晰地从与其具有相似属性的集合中进行定义区分的词语或者短语。（Sharnagat, "Named entity recognition: A literature survey, Center For Indian Language Technology, 2014）

#### 1.2 命名实体识别概念

命名实体识别（英语：Named Entity Recognition, 简称NER），又称作专名识别、命名实体，是指识别文本中的具体特定意义的实体。命名实体识别旨在从文本中提取实体并将其分类到预定义的分类集合当中。NER在NLP中有大量的应用，如信息抽取、问答系统、机器翻译等。

### 2. 研究内容

#### 2.1 研究对象

命名实体识别的研究主体一般包括三大类和七小类。三大类分别是实体类、时间类和数字类。七小类分别是人名、地名、机构名、日期、货币和百分比。命名实体识别就是识别文本中的这三大类、七小类的实体。命名实体识别的任务可以分解成两个子任务即实体边界（Entity Boundaries）确定和实体类别(Entity Types)划分。

#### 2.2 实体类别

其中，由于时间、货币和百分比等具有较为规范的规律，可以依据正则表达式等进行识别。而人名、地名、机构名等用字较为灵活，识别难度比较大。所以命名实体识别的主要研究领域也就是对人名、地名、机构名等的实体的识别。

#### 2.3 实体领域

在实际应用过程中，还需要根据具体的应用场景来确定。不同的应用场景需要对不同的实体识别进行优化。比如，在面向教育领域，经常将餐厅、学校、教师、学生等作为命名实体；面向体育领域，经常会将分数、跑步、篮球等作为命名实体。在这种情况下，一种领域的模型在应用于另一领域时就会出现严重的性能下降。（孙镇, 王惠临. 命名实体识别研究进展综述. 现代图书情报技术, 2010, 26(6): 42-47）

#### 2.4 语种

命名实体识别还要依据不同的语种进行特别的调整。例如，由于英文文本在命名实体的识别过程中只需要考虑词本身的特征而不涉及分词问题，实现难度相比中文就比较低。汉语命名实体的生成规律、语法结构、应用环境等更加复杂，很难提取构成规则，因此不可能用一种识别模型应用于所有的命名实体识别任务。

命名实体识别是各种NLP应用的基础，是NLP研究绕不过去的基础性问题。对NER的深入研究有助于整个NLP的发展，对NLP的快速应用具有重要意义。

### 3. 发展历程

![](https://pic2.zhimg.com/80/v2-ae75a69efab8b5d0f6701cf752322649_hd.jpg)



<center>https://zhuanlan.zhihu.com/p/43061858</center>


NER最初在第六届信息理解会议（MUC-6）上被提出。（Grishman R, Sundheim B. **Message Understand ing Conference-6: A Brief History[C]**.* 1996.）此后，研究者对NER进行了深入的研究。依据时间线，我们可以将NER方法大致分为以下四种：（Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li， A Survey on deep learning for Named entity Recognition， 2018）

* 基于规则的方法。依赖于手工设置的规则，不需要标注的数据。
* 无监督学习的方法。依赖于非监督机器学习算法，不需要标注的数据。
* 基于特征的监督学习。依赖于监督学习算法以及优良的特征表示。
* 深度学习。一种端到端的策略，可以自动探测所需的分类以及特征表示。

### 4. 国内外研究

命名实体识别在自然语言处理中占据很重要的位置，国内外都对此进行了深入的研究并形成了一定的成果，产生了很多专门的dataset以及toolkit。

#### 4.1 Datasets

![1561124561647](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1561124561647.png)

<center>图片来自Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li， A Survey on deep learning for Named entity Recognition， 2018</center>
上表列出了目前应用比较广泛的Datasets。这些并标注好的数据集会在NER算法研究过程中帮助研究者进行验证和训练。这些训练集具有一定的特征，因此研究者需要针对不同的应用范畴选取不同的训练集。

例如，NYT全称是The New York Times Annotated Corpus。纽约时报注释语料库包含超过180万篇文章。这些文章主要是在1987年1月1日至2007年6月19日纽约时报撰写和发表的。该集合包含超过650,000个文章 - 摘要对，这些数据对可能有助于自动文档摘要的算法的开发和评估。

#### 4.2 Off-the-shelf Tools

![1561124724637](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1561124724637.png)

<center>图片来自Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li， A Survey on deep learning for Named entity Recognition， 2018</center>
上表列出了目前广泛应用的NER工具。例如，NLTK能够为50多种语料库和词汇资源提供易于使用的结构，并且提供了一套用于分类、标记化、词干化、标记、解析和语义推理的文本处理库，和用于工业级NLP库的包装器。

#### 4.3 研究机构

国内外关于命名实体识别的主要研究机构和相关工作如下：(1) 国外研究机构主要是对英语等语言的实体识别，代表机构包括斯坦福研究所人工智能中心、因特尔研究中心、微软研究院、雅虎研究中心、日本东京大学等。(2) 国内主要解决中文命名实体识别，代表机构包括中科院计算所、微软中国研究院、哈尔滨工业大学自然语言处理实验室、北京语言大学语言信息处理研究所、北京理工大学自然语言处理研究室和复旦大学自然语言处理研究室等。（[https://bainingchao.github.io/2019/02/13/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF/](https://bainingchao.github.io/2019/02/13/命名实体识别技术/)）



## 二、评价方式

#### 1. 完全评价匹配（Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li， A Survey on deep learning for Named entity Recognition， 2018）

所谓完全评价匹配就是指实体边界和实体类型都符合要求。完全匹配评价的参数主要有三个Precision, Recall和F-score。这些参数是通过计算TP,FP和FN得来的。

* TP：被NER正确识别为实体
* FP:    被NER错误识别为对应实体
* FN：被标注数据标注的实体但是没有被NER识别出来

$$
Precision = \frac{TP}{TP+FP}   
\\
Recall = \frac{TP}{TP+FN}
\\
F_{\beta} = \frac{(\beta ^2 + 1) \times precision \times recall}{(\beta ^2) \times precision + recall}
\\
$$

第三个公式由Sang E F（Sang E F, De Meulder F. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition[J]. arXiv preprint cs/0306050, 2003.）提出。其中当$\beta = 1$时：
$$
F_{score} = \frac{2 \times Precision \times Recall}{Precision + Recall}
$$


#### 2. 其他评价方式

ACE提出了一个更复杂的评估程序。它解决了部分匹配和错误类型等问题，并考虑了命名实体的子类型。然而，这是有问题的，因为只有当参数固定时，最终得分才具有可比性[1]，[20]，[21]。复杂的评估方法不直观，难以进行错误分析。因此，复杂的评估方法在最近的NER研究中没有被广泛使用。

ACE（Doddington G R, Mitchell A, Przybocki M A, et al. The Automatic Content Extraction (ACE) Program-Tasks, Data, and Evaluation[C]//Lrec. 2004, 2: 1.）提出了一个复杂的评分标准。分数被定义为整个系统输出实体的综合。
$$
EDT\_Value_{sys} = \sum_i value_of_sys_entity_i
\\
Value_{sys\_entity} = Entity\_Value(sys\_entity) \times \sum_m Mention\_Value(sys\_mention_m)
$$
它解决了部分匹配和错误类型等问题，并考虑了命名实体的子类型。然而，这是有问题的，因为只有当参数固定时，最终得分才具有可比性。

这些评价方式并没有被广泛使用。



## 三、命名实体识别方法

### 1. 基于规则

Farmakiotou D, Karkaletsis V, Koutsias J, et al. Rule-based named entity recognition for Greek financial texts[C]//Proceedings of the Workshop on Computational lexicography and Multimedia Dictionaries (COMLEX 2000). 2000: 75-78.

基于规则的命名实体依赖于手工设置规则。规则主要是基于语义学、领域专有名词等进行设置。通常包含在NER系统中的词汇资源是词典，以地名词典列表的形式，以及语法，负责识别不在词典中或出现在多个地名词典列表中的实体。现有的NER系统属于以下类型：

* 系统基于手工制作的语法和地名录。典型的有LaSIE, LaSIE II, FASTUS
* 系统利用机器学习技术自动获取NER词汇资源。
* 结合前两种方法的系统，如爱丁堡大学的LTG系统

基于规则的方法命名实体识别的方法的缺点是相当明显的。首先是需要人工花费大量时间对语言学进行研究，才能构建出合适的规则。其次，这种方法仅适用于小数据集。当数据集逐渐增大时，这种弊端就会显现出来。数据集越大，无论是词义还是实体类型都变得异常复杂，以至于很难设计出较好的规则。

### 2.  基于统计机器学习的方法

鉴于基于规则的命名实体识别方法的弊端，人们逐渐提出了基于统计的机器学习方法。

基于机器学习的NER归根结底都是分类的方法。（Liu Liu, Wang Dongbo, A Review on Named Entity Recognition, 2018）给定命名实体的多个分类，再使用模型对文本中的实体进行分类。另一种是序列化标注方法。（Research on Named Entity Recognition ZhANG Xiao-Yan WANG Ting CHEN Huo-Wang）。

序列化 标注是目前最为有效，也是最普遍的NER方法。经 典机器学习分类模型如HMM（S.R. Eddy, "Hidden markov models, Current opinion in structural biology, vol 6, no 3, pp. 361-365, 1996）、CRF (J. Lafferty, A McCallum, and F C Pereira, "Conditional random fields: Probabilistic models for segmenting and labeling sequence data, 2001)和SVM(Isozaki H, Kazawa H. Efficient support vector classifiers for named entity recognition[C]/ Proceedings of the 19th Interna- tional Conference on Computational Linguistics. Stroudsburg: Association for Computational Linguistics, 2002, 1: 1-7)都被成功地用来进行命名实体的序列化标 注，且获得了较好的效果。

目前采用更多的是将基于统计的机器学习方法与基于规则的命名实体识别方法结合起来。这样既能够通过统计的方式降低人工设计规则的成本，另一方面通过手工设置规则的方式可以提高准确率、召回率和F值。

但是基于统计的缺点就在于需要大量标注好的数据。

### 3. 深度学习

深度学习是近年来机器学习领域发展最为迅速的领域。深度学习是基于深层神经网络（Deep Neural Network, DNN) 的学习方法的别称（刘树杰，董力，张家俊，深度学习在自然语言处理中的应用，中国计算机学会通讯，2015.03）。

近年来，基于深度学习的NER模型逐渐成为研究的重点。相比于传统的NER方法，深度学习方法可以自动进行隐层特征的识别，可以自动对数据进行特征识别和抽象。深度学习的优势就在于可以使用非监督学习或半监督学习和分层特征提取高效演算法来替代手工取得特征。

CoNLL 2003 是用于命名实体识别（NER）的标准英语数据集，其中主要包含四种命名实体：人、地点、组织和其它实体。NER 属于自然语言处理问题，其中词典非常有用。Collobert 等人（2011）首次通过用地名索引特征增强的神经架构实现了具有竞争性的结果。Chiu and Nichols（2015）将词典特征、字符嵌入和单词嵌入串联起来，然后将其作为双向 LSTM 的输入。(<https://www.jiqizhixin.com/articles/2019-02-28-12>)

另一方面，Lample 等人（2016）仅靠字符和单词嵌入，通过在大型无监督语料库上进行预训练嵌入实现了具有竞争性的结果。与 POS 标签类似，CRF 也提升了 NER 的性能，这一点在 Lample 等人（2016）的《Neural Architectures for Named Entity Recognition》中得到了证实。总体来说，带有 CRF 的双向 LSTM 对于结构化预测是一个强有力的模型。(<https://www.jiqizhixin.com/articles/2019-02-28-12>)

Passos 等人（2014）提出经修正的 skip-gram 模型，以更好地学习与实体类型相关的词嵌入，此类词嵌入可以利用来自相关词典的信息。Luo 等人（2015）联合优化了实体以及实体和知识库的连接。Strubell 等人（2017）提出用空洞卷积，他们希望通过跳过某些输入来定义更宽的有效输入，因此实现更好的并行化和上下文建模。该模型在保持准确率的同时展示出了显著的加速。(<https://www.jiqizhixin.com/articles/2019-02-28-12>)

RNN是最广泛使用的上下文解码器之一，并且CRF是标签解码器的最常见选择。特别是，BiLSTM-CRF是使用深度学习的NER最常见的架构。 NER系统成功的关键在很大程度上依赖于其输入表示。（Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li， A Survey on deep learning for Named entity Recognition， 2018）

## 四、 命名实体的挑战

无论是监督学习还是深度学习，NER都需要有大量的已经标注好的数据进行模型训练。（Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li， A Survey on deep learning for Named entity Recognition， 2018）而文本标注本身是一件浩大的工程。目前，就缺乏大规模、多样性的标注好的数据。（隋臣，基于深度学习的中文命名实体识别研究，2017）

另一方面，由于语义上的歧义，一个单词往往具有多重意思。这些具有多重含义的单词会对模型训练造成混淆，从而降低模型的识别率。同时，业界对标注规范、标注标准没有进行明确界定，这导致了标注的不统一。（Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li， A Survey on deep learning for Named entity Recognition， 2018）

## 五、未来方向

