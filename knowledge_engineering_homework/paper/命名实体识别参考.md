# [维基百科  命名实体识别]([https://zh.wikipedia.org/wiki/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB](https://zh.wikipedia.org/wiki/命名实体识别))

命名实体识别（英语：Named Entity Recognition, 简称NER），又称作专名识别、命名实体，是指识别文本中的具有特定意义的实体，主要包括任命、地名、机构名等、专有名词等，以及时间、货币、数量、比例数值等文字。指的是可以用专有名词标识的事物，一个命名实体一般代表唯一一个具体事物个体，包括人名、地名等。

NER属于从非结构化文本中分类和定位命名实体感情的子任务，其过程是从是非结构化文本表达式中产生专有名词标注信息的命名实体表达式，目前NER有两个显著的问题，即识别和分类。例如，「欧巴马是美国总统」的「欧巴马」和「美国」都代表一个具体事物，因此都是命名实体。而「总统」不代表一个具体事物，因此不是命名实体。

# [百度百科  命名实体识别]([https://baike.baidu.com/item/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/6968430?fr=aladdin](https://baike.baidu.com/item/命名实体识别/6968430?fr=aladdin))

作用：

命名实体识别是信息提取、问答系统、句法分析、机器翻译、面向Semantic Web的元数据标注等应用领域的重要基础工具，在自然语言处理技术走向实用化的过程中占有重要地位。一般来说，命名实体识别的任务就是识别出待处理文本中三大类（实体类、时间类和数字类）、七小类（人名、机构名、地名、时间、日期、货币和百分比）命名实体。

# [一文详解深度学习在命名实体识别(NER)中的应用](<https://zhuanlan.zhihu.com/p/43061858>)

从自然语言处理的流程来看，NER可以看作词法分析中未登录词识别的一种，是未登录词中数量最多、识别难度最大、对分词效果影响最大问题。

NER当前并不算是一个大热的研究课题，因为学术界部分学者认为这是一个已经解决的问题。当然也有学者认为这个问题还没有得到很好地解决，原因主要有：命名实体识别只是在有限的文本类型（主要是新闻语料中）和实体类别（主要是人名、地名、组织机构名）中取得了不错的效果；与其他信息检索领域相比，实体命名评测预料较小，容易产生过拟合；命名实体识别更侧重高召回率，但在信息检索领域，高准确率更重要；通用的识别多种类型的命名实体的系统性能很差。

![](https://pic2.zhimg.com/80/v2-ae75a69efab8b5d0f6701cf752322649_hd.jpg)

在基于机器学习的方法中，NER被当作序列标注问题。利用大规模语料来学习出标注模型，从而对句子的各个位置进行标注。**NER 任务中的常用模型包括生成式模型HMM、判别式模型CRF等。**条件随机场（ConditionalRandom Field，CRF）是NER目前的主流模型。它的目标函数不仅考虑输入的状态特征函数，而且还包含了标签转移特征函数。在训练时可以使用SGD学习模型参数。在已知模型时，给输入序列求预测输出序列即求使目标函数最大化的最优序列，是一个动态规划问题，可以使用Viterbi算法解码来得到最优标签序列。**CRF的优点在于其为一个位置进行标注的过程中可以利用丰富的内部及上下文特征信息。**



# [**命名实体识别研究进展综述**](<http://manu44.magtech.com.cn/Jwk_infotech_wk3/article/2010/1003-3513/1003-3513-26-6-42.html>)

国外对于英文命名实体识别的研究开始比较早。1991年Rau在第7届IEEE人工智能应用会议上发表了“抽取和识别公司名称”的有关研究文章,首次描述了抽取和识别公司名称的系统,该系统主要采用启发式算法和手工编写规则的方法[[ 3](http://manu44.magtech.com.cn/Jwk_infotech_wk3/article/2010/1003-3513/1003-3513-26-6-42.html#R3)]。1996年,命名实体评测作为信息抽取的一个子任务被引入MUC-6[[ 4](http://manu44.magtech.com.cn/Jwk_infotech_wk3/article/2010/1003-3513/1003-3513-26-6-42.html#R4)],在其后的MUC-7的MET-2[[ 5](http://manu44.magtech.com.cn/Jwk_infotech_wk3/article/2010/1003-3513/1003-3513-26-6-42.html#R5)]以及IEER-99、CoNLL-2002、CoNLL-2003、IREX、LREC等一系列国际会议中,命名实体识别都被作为其中的一项指定任务。

由于英文命名实体的识别中只需考虑词本身的特征而不涉及分词问题,因此实现难度相对较低。根据MUC以及ACE的评测结果,测试的准确率、召回率、F1值目前大多可以达到90%左右。



# [信息抽取之实体抽取](<https://blog.csdn.net/feng_zhiyu/article/details/80246690>)

1.命名实体识别的主要任务： 
要识别出文本中出现的专有名称和有意义的数量短语并加以归类。

2.命名实体识别的主要研究内容：

就整个的命名实体识别的研究结果而言，时间表达式和数字表达式的识别相对简单，其规则的设计、数据的统计训练等也比较容易。而对于实体中的组织名、人名、地名，因为其具有开放性和发展性的特点，而且构成规律有很大的随意性，所以其识别就可能会有较多的错选或漏选。现在大多数的命名实体识别的研究都集中于对这三种实体的识别技术的研究。

3.命名实体识别的发展历程：

基于规则的方法->基于统计的方法->混合方法

4.汉语命名实体识别中的特殊难点：

（1）分词：[边界]()模糊不仅存在于非实体词之间，也出现于实体词和非实体词之间。

（2）汉语命名实体的生成规律以及结构更加复杂，尤其是缩略语的表示形式具有多样性，很难提取构成规则，因此不可能用一种识别模型应用于所有的命名实体。

（3）与西方语言比较，汉语缺少在命名实体识别中起重要作用的词形变换特征。

（4）汉语中除比较特殊的字词外，命名实体也可包含普通字词。

（5）能用于汉语命名实体识别的开放型语料还很少，因此一方面需要开发大型命名实体标注语料库，另一方面研究不依赖大型命名实体标注文本库的算法也具有重要意义。

5.命名实体识别的结果：

（1）正确（correct） ：系统识别结果和标准结果相同。

（2）丢失（missing）：系统未识别而标准结果中有。

（3）虚假（spurious）：系统识别但标准结果中没有。

6.衡量命名实体识别系统性能主要的两个评价指标：

查全率：正确/（正确+丢失）

查准率：正确/（正确+虚假）

有时为了综合评价系统的性能，通常还计算查全率和查准率的加权几何平均值即F指数。

7.命名实体识别方法：

（1）基于规则：

如：NTU系统、FACILE系统、OKI系统。

缺点：缺乏鲁棒性和可移植性，对于每个新领域的文本都需要更新规则来保持最优性能，而这需要大量的专门知识和人力，代价往往非常大。

（2）基于统计：

如：n元模型、隐马尔科夫模型（HMM）、最大熵模型（ME）、决策树、基于转换的学习方法、推进方法、表决感知器方法、条件马尔科夫模型等。评价性能最好的是HMM。而ME因其自身的特点仍是当前主要的研究方向。

缺点：性能较基于规则的方法而言偏低，因为基于统计的方法获取的概率知识总赶不上人类专家的专业知识的可靠性，而且有些知识获取必需专家的经验。

（3）混合方法：

借助规则知识及早剪枝，再用统计模型是比较好的方法。





# [命名实体识别技术]([https://bainingchao.github.io/2019/02/13/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF/](https://bainingchao.github.io/2019/02/13/命名实体识别技术/))

命名实体识别(Named Entity Recognizer,NER)在第六届信息理解会议(MUC-6)被提出后，人们的视野便聚焦在信息抽取 (Information Extraction)问题上(即如何从半结构化、非结构化文本中抽取出结构化信息)。此外，命名实体识别也是信息抽取、本体构建、问答系统等自然语言处理任务的基础工作。





# A survey on deep learning for named entity recognition

* "Named Entity"的概念第一次在MUC-6提出
* NE分为广义和狭义概念
* A survey of named entity recofnition and clasification 2007
* A named entity is 







# CNN

![1561107903193](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1561107903193.png)

<center>https://www.youtube.com/watchv=scu4ALuF9NM&list=PLua227btV7cTc26SD9kZfGRrQfRzy2K1o&index=6</center>



# RNN

![1561108335074](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1561108335074.png)

<center>https://www.youtube.com/watchv=7uWGxBH5m40&list=PLua227btV7cTc26SD9kZfGRrQfRzy2K1o&index=7</center>

原始的RNN结构会出现梯度弥散和梯度爆炸的问题

使用LSTM和GRU可以解决这个问题

![1561108512141](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1561108512141.png)

<center>https://www.youtube.com/watchv=7uWGxBH5m40&list=PLua227btV7cTc26SD9kZfGRrQfRzy2K1o&index=7</center>

![1561108523364](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1561108523364.png)

<center>https://www.youtube.com/watchv=7uWGxBH5m40&list=PLua227btV7cTc26SD9kZfGRrQfRzy2K1o&index=7</center>

![1561115276473](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1561115276473.png)

<center>https://www.youtube.com/watch?v=rri0KMZmdTw&list=PLua227btV7cTc26SD9kZfGRrQfRzy2K1o&index=4</center>

