{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, nth_layer, activation_function=None):\n",
    "    layer_name = \"layer%s\" % nth_layer\n",
    "    with tf.name_scope(\"layer\"):\n",
    "        with tf.name_scope('Weights'):\n",
    "            Weights = tf.Variable(tf.random_uniform([in_size, out_size]), name='W')\n",
    "            tf.summary.histogram(layer_name + '/weights', Weights)\n",
    "        \n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1,out_size]) + 0.1, name='b')\n",
    "            tf.summary.histogram(layer_name + '/biases', biases)\n",
    "            \n",
    "        with tf.name_scope('Wx_pluse_b'):\n",
    "            Wx_pluse_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        \n",
    "        if activation_function == None:\n",
    "            outputs = Wx_pluse_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_pluse_b)\n",
    "        \n",
    "        tf.summary.histogram(layer_name + 'outputs', outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50856667],\n",
       "       [ 0.50959252],\n",
       "       [ 0.4980469 ],\n",
       "       [ 0.49994706],\n",
       "       [ 0.47170675],\n",
       "       [ 0.40781388],\n",
       "       [ 0.48110933],\n",
       "       [ 0.38479345],\n",
       "       [ 0.41606389],\n",
       "       [ 0.37749565],\n",
       "       [ 0.37986524],\n",
       "       [ 0.35959481],\n",
       "       [ 0.42867627],\n",
       "       [ 0.41171553],\n",
       "       [ 0.18682417],\n",
       "       [ 0.28858489],\n",
       "       [ 0.16644271],\n",
       "       [ 0.2745607 ],\n",
       "       [ 0.23827867],\n",
       "       [ 0.3081676 ],\n",
       "       [ 0.26709169],\n",
       "       [ 0.20718224],\n",
       "       [ 0.23075176],\n",
       "       [ 0.22261726],\n",
       "       [ 0.13130188],\n",
       "       [ 0.17744671],\n",
       "       [ 0.12890994],\n",
       "       [ 0.23988622],\n",
       "       [ 0.01910367],\n",
       "       [ 0.17093307],\n",
       "       [ 0.10244213],\n",
       "       [ 0.13586436],\n",
       "       [ 0.03267581],\n",
       "       [ 0.11483321],\n",
       "       [ 0.11745671],\n",
       "       [ 0.01134738],\n",
       "       [ 0.11658773],\n",
       "       [ 0.0337604 ],\n",
       "       [ 0.06399781],\n",
       "       [-0.02504961],\n",
       "       [ 0.05453265],\n",
       "       [-0.01391911],\n",
       "       [ 0.01047356],\n",
       "       [-0.00623312],\n",
       "       [ 0.01974636],\n",
       "       [-0.02667617],\n",
       "       [-0.04458809],\n",
       "       [ 0.0407204 ],\n",
       "       [ 0.0071988 ],\n",
       "       [-0.13552586],\n",
       "       [-0.06284633],\n",
       "       [-0.10391794],\n",
       "       [-0.08895919],\n",
       "       [-0.05479592],\n",
       "       [-0.11197433],\n",
       "       [-0.10016319],\n",
       "       [-0.12803723],\n",
       "       [-0.1583363 ],\n",
       "       [-0.16952769],\n",
       "       [ 0.02483044],\n",
       "       [-0.13307187],\n",
       "       [-0.16507312],\n",
       "       [-0.12790062],\n",
       "       [-0.17860853],\n",
       "       [-0.17425045],\n",
       "       [-0.24752202],\n",
       "       [-0.21626321],\n",
       "       [-0.06070832],\n",
       "       [-0.2056823 ],\n",
       "       [-0.17923118],\n",
       "       [-0.2996497 ],\n",
       "       [-0.25144199],\n",
       "       [-0.25673954],\n",
       "       [-0.22305612],\n",
       "       [-0.3092372 ],\n",
       "       [-0.28892892],\n",
       "       [-0.20540082],\n",
       "       [-0.20736711],\n",
       "       [-0.22774206],\n",
       "       [-0.22534867],\n",
       "       [-0.28016816],\n",
       "       [-0.2036202 ],\n",
       "       [-0.28567438],\n",
       "       [-0.29127643],\n",
       "       [-0.24013111],\n",
       "       [-0.2839586 ],\n",
       "       [-0.36003446],\n",
       "       [-0.28884057],\n",
       "       [-0.38121445],\n",
       "       [-0.38350581],\n",
       "       [-0.28586784],\n",
       "       [-0.40001333],\n",
       "       [-0.40903064],\n",
       "       [-0.35242676],\n",
       "       [-0.40334353],\n",
       "       [-0.42121114],\n",
       "       [-0.32148979],\n",
       "       [-0.35044784],\n",
       "       [-0.36749782],\n",
       "       [-0.3283337 ],\n",
       "       [-0.39140485],\n",
       "       [-0.32453575],\n",
       "       [-0.29901071],\n",
       "       [-0.44382834],\n",
       "       [-0.42664878],\n",
       "       [-0.37240304],\n",
       "       [-0.51156906],\n",
       "       [-0.47697019],\n",
       "       [-0.48267079],\n",
       "       [-0.38157966],\n",
       "       [-0.39706597],\n",
       "       [-0.38670315],\n",
       "       [-0.46602537],\n",
       "       [-0.43421575],\n",
       "       [-0.45269964],\n",
       "       [-0.486614  ],\n",
       "       [-0.49599009],\n",
       "       [-0.41272937],\n",
       "       [-0.47462896],\n",
       "       [-0.46038575],\n",
       "       [-0.46613842],\n",
       "       [-0.45446173],\n",
       "       [-0.51166396],\n",
       "       [-0.44697906],\n",
       "       [-0.5417014 ],\n",
       "       [-0.58533632],\n",
       "       [-0.46904092],\n",
       "       [-0.43918879],\n",
       "       [-0.53387135],\n",
       "       [-0.54069105],\n",
       "       [-0.38676641],\n",
       "       [-0.57178625],\n",
       "       [-0.52201534],\n",
       "       [-0.53160298],\n",
       "       [-0.58773533],\n",
       "       [-0.46163502],\n",
       "       [-0.41903065],\n",
       "       [-0.51813183],\n",
       "       [-0.4902904 ],\n",
       "       [-0.49156457],\n",
       "       [-0.49518983],\n",
       "       [-0.49818892],\n",
       "       [-0.48294366],\n",
       "       [-0.52115632],\n",
       "       [-0.49083627],\n",
       "       [-0.55254537],\n",
       "       [-0.46144565],\n",
       "       [-0.46409006],\n",
       "       [-0.44352829],\n",
       "       [-0.58331945],\n",
       "       [-0.51178529],\n",
       "       [-0.51443537],\n",
       "       [-0.53067236],\n",
       "       [-0.58173418],\n",
       "       [-0.47180037],\n",
       "       [-0.4008961 ],\n",
       "       [-0.43082176],\n",
       "       [-0.48514112],\n",
       "       [-0.47543535],\n",
       "       [-0.45395807],\n",
       "       [-0.48540363],\n",
       "       [-0.53074105],\n",
       "       [-0.51555661],\n",
       "       [-0.48548843],\n",
       "       [-0.42852741],\n",
       "       [-0.4914496 ],\n",
       "       [-0.50268762],\n",
       "       [-0.51832979],\n",
       "       [-0.45103384],\n",
       "       [-0.45700227],\n",
       "       [-0.54654417],\n",
       "       [-0.50878157],\n",
       "       [-0.50898584],\n",
       "       [-0.43703351],\n",
       "       [-0.50760033],\n",
       "       [-0.45137417],\n",
       "       [-0.53950986],\n",
       "       [-0.51992869],\n",
       "       [-0.39189643],\n",
       "       [-0.51216633],\n",
       "       [-0.45103255],\n",
       "       [-0.56547638],\n",
       "       [-0.42773299],\n",
       "       [-0.55643293],\n",
       "       [-0.47239447],\n",
       "       [-0.48022387],\n",
       "       [-0.43277469],\n",
       "       [-0.41137292],\n",
       "       [-0.561358  ],\n",
       "       [-0.50843496],\n",
       "       [-0.34095321],\n",
       "       [-0.34102289],\n",
       "       [-0.4962358 ],\n",
       "       [-0.39105406],\n",
       "       [-0.38672961],\n",
       "       [-0.38479902],\n",
       "       [-0.38710134],\n",
       "       [-0.39805456],\n",
       "       [-0.35489172],\n",
       "       [-0.43417335],\n",
       "       [-0.3924531 ],\n",
       "       [-0.42840975],\n",
       "       [-0.32967738],\n",
       "       [-0.42521756],\n",
       "       [-0.36409648],\n",
       "       [-0.34017614],\n",
       "       [-0.34457956],\n",
       "       [-0.3357388 ],\n",
       "       [-0.34243044],\n",
       "       [-0.36445271],\n",
       "       [-0.32384514],\n",
       "       [-0.35833687],\n",
       "       [-0.26867592],\n",
       "       [-0.26809894],\n",
       "       [-0.31737329],\n",
       "       [-0.26954104],\n",
       "       [-0.21659239],\n",
       "       [-0.25749814],\n",
       "       [-0.37727119],\n",
       "       [-0.25395645],\n",
       "       [-0.26926687],\n",
       "       [-0.30729518],\n",
       "       [-0.27238383],\n",
       "       [-0.28255176],\n",
       "       [-0.29722094],\n",
       "       [-0.25328556],\n",
       "       [-0.27152781],\n",
       "       [-0.26169139],\n",
       "       [-0.22256537],\n",
       "       [-0.13990683],\n",
       "       [-0.15438087],\n",
       "       [-0.15495167],\n",
       "       [-0.16321628],\n",
       "       [-0.2593358 ],\n",
       "       [-0.16521456],\n",
       "       [-0.28664584],\n",
       "       [-0.12026379],\n",
       "       [-0.20093573],\n",
       "       [-0.15273779],\n",
       "       [-0.11912363],\n",
       "       [-0.11805267],\n",
       "       [-0.12007102],\n",
       "       [-0.14965424],\n",
       "       [-0.15923219],\n",
       "       [ 0.00529983],\n",
       "       [-0.13550835],\n",
       "       [-0.13970152],\n",
       "       [-0.14638809],\n",
       "       [-0.01244463],\n",
       "       [-0.08812238],\n",
       "       [-0.07048747],\n",
       "       [-0.0223695 ],\n",
       "       [-0.09607791],\n",
       "       [-0.02791753],\n",
       "       [-0.0158078 ],\n",
       "       [ 0.00745107],\n",
       "       [ 0.05389645],\n",
       "       [-0.01788879],\n",
       "       [-0.02911626],\n",
       "       [ 0.05955154],\n",
       "       [ 0.04071192],\n",
       "       [ 0.11967982],\n",
       "       [ 0.07261859],\n",
       "       [ 0.13208772],\n",
       "       [ 0.02226643],\n",
       "       [ 0.04526405],\n",
       "       [ 0.11664214],\n",
       "       [ 0.06461113],\n",
       "       [ 0.1109819 ],\n",
       "       [ 0.15005484],\n",
       "       [ 0.18976373],\n",
       "       [ 0.1404823 ],\n",
       "       [ 0.21682774],\n",
       "       [ 0.22305382],\n",
       "       [ 0.19644581],\n",
       "       [ 0.22092112],\n",
       "       [ 0.2305424 ],\n",
       "       [ 0.24753732],\n",
       "       [ 0.24513127],\n",
       "       [ 0.27020874],\n",
       "       [ 0.25587947],\n",
       "       [ 0.29595033],\n",
       "       [ 0.30929651],\n",
       "       [ 0.37633069],\n",
       "       [ 0.29977273],\n",
       "       [ 0.32393827],\n",
       "       [ 0.32476872],\n",
       "       [ 0.34719352],\n",
       "       [ 0.30981305],\n",
       "       [ 0.36615683],\n",
       "       [ 0.38463395],\n",
       "       [ 0.37771834],\n",
       "       [ 0.4586379 ],\n",
       "       [ 0.44672352],\n",
       "       [ 0.42842692],\n",
       "       [ 0.51339091],\n",
       "       [ 0.46225739],\n",
       "       [ 0.47575312],\n",
       "       [ 0.54079745],\n",
       "       [ 0.49208155]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = np.linspace(-1,1,300)[:,np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define placeholder\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = add_layer(xs, 1, 10, nth_layer=1, activation_function=tf.nn.relu)\n",
    "prediction = add_layer(layer1, 10, 1, nth_layer=2, activation_function=None)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "with tf.name_scope(\"trains\"):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={xs:x_data, ys:y_data})\n",
    "    if i % 100 == 0:\n",
    "        result = sess.run(merged, feed_dict={xs:x_data, ys:y_data})\n",
    "        writer.add_summary(result, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
